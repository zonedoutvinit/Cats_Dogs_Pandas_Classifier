{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "#Load libraries\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import glob\r\n",
    "import torch.nn as nn\r\n",
    "from torchvision.transforms import transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.optim import Adam\r\n",
    "from torch.autograd import Variable\r\n",
    "import torchvision\r\n",
    "import pathlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "#checking for device\r\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#Transforms\r\n",
    "transformer=transforms.Compose([\r\n",
    "    transforms.Resize((150,150)),\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\r\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
    "                        [0.5,0.5,0.5])\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Dataloader\r\n",
    "\r\n",
    "#Path for training and testing directory\r\n",
    "train_path='../datasets/test'\r\n",
    "test_path='../datasets/train'\r\n",
    "\r\n",
    "train_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\r\n",
    "    batch_size=64, shuffle=True\r\n",
    ")\r\n",
    "test_loader=DataLoader(\r\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\r\n",
    "    batch_size=32, shuffle=True\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#categories\r\n",
    "root=pathlib.Path(train_path)\r\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print(classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['cats', 'dogs', 'pandas']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "#CNN Network\r\n",
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self,num_classes=3):\r\n",
    "        super(ConvNet,self).__init__()\r\n",
    "        \r\n",
    "        #Output size after convolution filter\r\n",
    "        #((w-f+2P)/s) +1\r\n",
    "        \r\n",
    "        #Input shape= (256,3,150,150)\r\n",
    "        \r\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (256,12,150,150)\r\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\r\n",
    "        #Shape= (256,12,150,150)\r\n",
    "        self.relu1=nn.ReLU()\r\n",
    "        #Shape= (256,12,150,150)\r\n",
    "        \r\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\r\n",
    "        #Reduce the image size be factor 2\r\n",
    "        #Shape= (256,12,75,75)\r\n",
    "        \r\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (256,20,75,75)\r\n",
    "        self.relu2=nn.ReLU()\r\n",
    "        #Shape= (256,20,75,75)\r\n",
    "        \r\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\r\n",
    "        #Shape= (256,32,75,75)\r\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\r\n",
    "        #Shape= (256,32,75,75)\r\n",
    "        self.relu3=nn.ReLU()\r\n",
    "        #Shape= (256,32,75,75)\r\n",
    "        \r\n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)      \r\n",
    "        #Feed forwad function\r\n",
    "        \r\n",
    "    def forward(self,input):\r\n",
    "        output=self.conv1(input)\r\n",
    "        output=self.bn1(output)\r\n",
    "        output=self.relu1(output)\r\n",
    "            \r\n",
    "        output=self.pool(output)\r\n",
    "            \r\n",
    "        output=self.conv2(output)\r\n",
    "        output=self.relu2(output)\r\n",
    "            \r\n",
    "        output=self.conv3(output)\r\n",
    "        output=self.bn3(output)\r\n",
    "        output=self.relu3(output) \r\n",
    "            \r\n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\r\n",
    "            \r\n",
    "        output=output.view(-1,32*75*75)\r\n",
    "            \r\n",
    "            \r\n",
    "        output=self.fc(output)\r\n",
    "            \r\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model=ConvNet(num_classes=3).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#Optmizer and loss function\r\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\r\n",
    "loss_function=nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "num_epochs=10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "#calculating the size of training and testing images\r\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\r\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "print(train_count,test_count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1200 3002\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "#Model training and saving best model\r\n",
    "\r\n",
    "best_accuracy=0.0\r\n",
    "\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    \r\n",
    "    #Evaluation and training on training dataset\r\n",
    "    model.train()\r\n",
    "    train_accuracy=0.0\r\n",
    "    train_loss=0.0\r\n",
    "    \r\n",
    "    for i, (images,labels) in enumerate(train_loader):            \r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        outputs=model(images)\r\n",
    "        loss=loss_function(outputs,labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        \r\n",
    "        train_loss+= loss.cpu().data*images.size(0)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        \r\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "        \r\n",
    "    train_accuracy=train_accuracy/train_count\r\n",
    "    train_loss=train_loss/train_count\r\n",
    "    \r\n",
    "    \r\n",
    "    # Evaluation on testing dataset\r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    test_accuracy=0.0\r\n",
    "    for i, (images,labels) in enumerate(test_loader):            \r\n",
    "        outputs=model(images)\r\n",
    "        _,prediction=torch.max(outputs.data,1)\r\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\r\n",
    "    \r\n",
    "    test_accuracy=test_accuracy/test_count\r\n",
    "    \r\n",
    "    \r\n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\r\n",
    "    \r\n",
    "    #Save the best model\r\n",
    "    if test_accuracy>best_accuracy:\r\n",
    "        torch.save(model.state_dict(),'bestsofar.model')\r\n",
    "        best_accuracy=test_accuracy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Train Loss: tensor(17.2409) Train Accuracy: 0.49166666666666664 Test Accuracy: 0.34243837441705527\n",
      "Epoch: 1 Train Loss: tensor(7.0151) Train Accuracy: 0.5791666666666667 Test Accuracy: 0.5942704863424384\n",
      "Epoch: 2 Train Loss: tensor(3.8704) Train Accuracy: 0.6866666666666666 Test Accuracy: 0.6718854097268487\n",
      "Epoch: 3 Train Loss: tensor(1.9877) Train Accuracy: 0.7633333333333333 Test Accuracy: 0.6845436375749501\n",
      "Epoch: 4 Train Loss: tensor(1.0224) Train Accuracy: 0.8233333333333334 Test Accuracy: 0.6885409726848768\n",
      "Epoch: 5 Train Loss: tensor(1.2855) Train Accuracy: 0.8275 Test Accuracy: 0.6835443037974683\n",
      "Epoch: 6 Train Loss: tensor(0.9195) Train Accuracy: 0.8433333333333334 Test Accuracy: 0.6795469686875416\n",
      "Epoch: 7 Train Loss: tensor(0.4605) Train Accuracy: 0.9258333333333333 Test Accuracy: 0.673217854763491\n",
      "Epoch: 8 Train Loss: tensor(0.2930) Train Accuracy: 0.9366666666666666 Test Accuracy: 0.6708860759493671\n",
      "Epoch: 9 Train Loss: tensor(0.1957) Train Accuracy: 0.9525 Test Accuracy: 0.6688874083944037\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "c12c9a3ab46614ebb53a25bfb0e0365553fe12c26a768f893745d73ed1857dda"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}